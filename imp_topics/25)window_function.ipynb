{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a38e8947",
   "metadata": {},
   "source": [
    "### Window Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb86f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number, rank,dense_rank\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"window\").getOrCreate()\n",
    "\n",
    "emp_data = emp_data = [\n",
    "    # IT – 5 records\n",
    "    {\"name\": \"Arun\",     \"dept\": \"IT\",        \"salary\": 80000},\n",
    "    {\"name\": \"Meena\",    \"dept\": \"IT\",        \"salary\": 85000},\n",
    "    {\"name\": \"Kiran\",    \"dept\": \"IT\",        \"salary\": 80000},  # repeated\n",
    "    {\"name\": \"Sanjay\",   \"dept\": \"IT\",        \"salary\": 90000},\n",
    "    {\"name\": \"Priya\",    \"dept\": \"IT\",        \"salary\": 85000},  # repeated\n",
    "\n",
    "    # HR – 5 records\n",
    "    {\"name\": \"Ravi\",     \"dept\": \"HR\",        \"salary\": 60000},\n",
    "    {\"name\": \"Divya\",    \"dept\": \"HR\",        \"salary\": 62000},\n",
    "    {\"name\": \"Vikas\",    \"dept\": \"HR\",        \"salary\": 60000},  # repeated\n",
    "    {\"name\": \"Anu\",      \"dept\": \"HR\",        \"salary\": 65000},\n",
    "    {\"name\": \"Rahul\",    \"dept\": \"HR\",        \"salary\": 62000},  # repeated\n",
    "\n",
    "    # Finance – 5 records\n",
    "    {\"name\": \"Anjali\",   \"dept\": \"Finance\",   \"salary\": 95000},\n",
    "    {\"name\": \"Pooja\",    \"dept\": \"Finance\",   \"salary\": 97000},\n",
    "    {\"name\": \"Suresh\",   \"dept\": \"Finance\",   \"salary\": 95000},  # repeated\n",
    "    {\"name\": \"Kavya\",    \"dept\": \"Finance\",   \"salary\": 98000},\n",
    "    {\"name\": \"Nitin\",    \"dept\": \"Finance\",   \"salary\": 97000},  # repeated\n",
    "\n",
    "    # Sales – 5 records\n",
    "    {\"name\": \"Rohit\",    \"dept\": \"Sales\",     \"salary\": 70000},\n",
    "    {\"name\": \"Tanya\",    \"dept\": \"Sales\",     \"salary\": 72000},\n",
    "    {\"name\": \"Naveen\",   \"dept\": \"Sales\",     \"salary\": 70000},  # repeated\n",
    "    {\"name\": \"Sneha\",    \"dept\": \"Sales\",     \"salary\": 75000},\n",
    "    {\"name\": \"Karan\",    \"dept\": \"Sales\",     \"salary\": 72000}   # repeated\n",
    "]\n",
    "\n",
    "\n",
    "df = spark.createDataFrame(data=emp_data)\n",
    "win = Window.partitionBy(\"dept\").orderBy(\"salary\")\n",
    "\n",
    "df = df.withColumn(\"row_number\", row_number().over(win)) \\\n",
    "       .withColumn(\"rank\", rank().over(win)) \\\n",
    "       .withColumn(\"dense_rank\", dense_rank().over(win)) \n",
    "\n",
    "df.select('name','dept','salary',\"row_number\",\"rank\",\"dense_rank\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f828f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "\n",
    "employees = [\n",
    "    {\"emp_id\": 1, \"name\": \"Arun\",  \"dept\": \"IT\",       \"experience\": 2,  \"salary\": 45000},\n",
    "    {\"emp_id\": 2, \"name\": \"Meena\", \"dept\": \"HR\",       \"experience\": 6,  \"salary\": 65000},\n",
    "    {\"emp_id\": 3, \"name\": \"Kiran\", \"dept\": \"IT\",       \"experience\": 4,  \"salary\": 55000},\n",
    "    {\"emp_id\": 4, \"name\": \"Sachin\",\"dept\": \"Finance\",  \"experience\": 8,  \"salary\": 82000},\n",
    "    {\"emp_id\": 5, \"name\": \"Priya\", \"dept\": \"Finance\",  \"experience\": 1,  \"salary\": 40000},\n",
    "    {\"emp_id\": 6, \"name\": \"Deepa\", \"dept\": \"HR\",       \"experience\": 10, \"salary\": 90000},\n",
    "    {\"emp_id\": 7, \"name\": \"John\",  \"dept\": \"Marketing\",\"experience\": 3,  \"salary\": 48000},\n",
    "    {\"emp_id\": 8, \"name\": \"Riya\",  \"dept\": \"Marketing\",\"experience\": 7,  \"salary\": 70000}\n",
    "]\n",
    "\n",
    "spark  = SparkSession.builder.appName(\"udf\").getOrCreate()\n",
    "\n",
    "df = spark.createDataFrame(employees)      \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
